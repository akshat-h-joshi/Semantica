{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e573fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cb630da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'http://arxiv.org/abs/2512.11798v1',\n",
       " 'title': 'Particulate: Feed-Forward 3D Object Articulation',\n",
       " 'abstract': \"We present Particulate, a feed-forward approach that, given a single static 3D mesh of an everyday object, directly infers all attributes of the underlying articulated structure, including its 3D parts, kinematic structure, and motion constraints. At its core is a transformer network, Part Articulation Transformer, which processes a point cloud of the input mesh using a flexible and scalable architecture to predict all the aforementioned attributes with native multi-joint support. We train the network end-to-end on a diverse collection of articulated 3D assets from public datasets. During inference, Particulate lifts the network's feed-forward prediction to the input mesh, yielding a fully articulated 3D model in seconds, much faster than prior approaches that require per-object optimization. Particulate can also accurately infer the articulated structure of AI-generated 3D assets, enabling full-fledged extraction of articulated 3D objects from a single (real or synthetic) image when combined with an off-the-shelf image-to-3D generator. We further introduce a new challenging benchmark for 3D articulation estimation curated from high-quality public 3D assets, and redesign the evaluation protocol to be more consistent with human preferences. Quantitative and qualitative results show that Particulate significantly outperforms state-of-the-art approaches.\",\n",
       " 'published': '2025-12-12T18:59:51+00:00',\n",
       " 'updated': '2025-12-12T18:59:51+00:00',\n",
       " 'authors': ['Ruining Li',\n",
       "  'Yuxin Yao',\n",
       "  'Chuanxia Zheng',\n",
       "  'Christian Rupprecht',\n",
       "  'Joan Lasenby',\n",
       "  'Shangzhe Wu',\n",
       "  'Andrea Vedaldi'],\n",
       " 'category': 'cs.CV'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/arxiv_cs_ai.json\") as f:\n",
    "    papers = json.load(f)\n",
    "\n",
    "papers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c43759f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'http://arxiv.org/abs/2512.11783v1',\n",
       " 'title': 'Super Suffixes: Bypassing Text Generation Alignment and Guard Models Simultaneously',\n",
       " 'abstract': \"The rapid deployment of Large Language Models (LLMs) has created an urgent need for enhanced security and privacy measures in Machine Learning (ML). LLMs are increasingly being used to process untrusted text inputs and even generate executable code, often while having access to sensitive system controls. To address these security concerns, several companies have introduced guard models, which are smaller, specialized models designed to protect text generation models from adversarial or malicious inputs. In this work, we advance the study of adversarial inputs by introducing Super Suffixes, suffixes capable of overriding multiple alignment objectives across various models with different tokenization schemes. We demonstrate their effectiveness, along with our joint optimization technique, by successfully bypassing the protection mechanisms of Llama Prompt Guard 2 on five different text generation models for malicious text and code generation. To the best of our knowledge, this is the first work to reveal that Llama Prompt Guard 2 can be compromised through joint optimization.\\n  Additionally, by analyzing the changing similarity of a model's internal state to specific concept directions during token sequence processing, we propose an effective and lightweight method to detect Super Suffix attacks. We show that the cosine similarity between the residual stream and certain concept directions serves as a distinctive fingerprint of model intent. Our proposed countermeasure, DeltaGuard, significantly improves the detection of malicious prompts generated through Super Suffixes. It increases the non-benign classification rate to nearly 100%, making DeltaGuard a valuable addition to the guard model stack and enhancing robustness against adversarial prompt attacks.\",\n",
       " 'published': '2025-12-12T18:52:09+00:00',\n",
       " 'updated': '2025-12-12T18:52:09+00:00',\n",
       " 'authors': ['Andrew Adiletta',\n",
       "  'Kathryn Adiletta',\n",
       "  'Kemal Derya',\n",
       "  'Berk Sunar'],\n",
       " 'category': 'cs.CR'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fe63cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'http://arxiv.org/abs/2512.11781v1',\n",
       " 'title': 'Agile Flight Emerges from Multi-Agent Competitive Racing',\n",
       " 'abstract': 'Through multi-agent competition and the sparse high-level objective of winning a race, we find that both agile flight (e.g., high-speed motion pushing the platform to its physical limits) and strategy (e.g., overtaking or blocking) emerge from agents trained with reinforcement learning. We provide evidence in both simulation and the real world that this approach outperforms the common paradigm of training agents in isolation with rewards that prescribe behavior, e.g., progress on the raceline, in particular when the complexity of the environment increases, e.g., in the presence of obstacles. Moreover, we find that multi-agent competition yields policies that transfer more reliably to the real world than policies trained with a single-agent progress-based reward, despite the two methods using the same simulation environment, randomization strategy, and hardware. In addition to improved sim-to-real transfer, the multi-agent policies also exhibit some degree of generalization to opponents unseen at training time. Overall, our work, following in the tradition of multi-agent competitive game-play in digital domains, shows that sparse task-level rewards are sufficient for training agents capable of advanced low-level control in the physical world.\\n  Code: https://github.com/Jirl-upenn/AgileFlight_MultiAgent',\n",
       " 'published': '2025-12-12T18:48:50+00:00',\n",
       " 'updated': '2025-12-12T18:48:50+00:00',\n",
       " 'authors': ['Vineet Pasumarti', 'Lorenzo Bianchi', 'Antonio Loquercio'],\n",
       " 'category': 'cs.RO'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9e736cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average abstract length: 179.85 words\n"
     ]
    }
   ],
   "source": [
    "abstract_lengths = [len(p['abstract'].split()) for p in papers]\n",
    "print(f\"Average abstract length: {np.mean(abstract_lengths):.2f} words\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
